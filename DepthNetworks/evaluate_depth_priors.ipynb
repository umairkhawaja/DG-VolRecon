{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import struct\n",
    "import imageio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def read_pfm(filename):\n",
    "    file = open(filename, 'rb')\n",
    "    color = None\n",
    "    width = None\n",
    "    height = None\n",
    "    scale = None\n",
    "    endian = None\n",
    "\n",
    "    header = file.readline().decode('utf-8').rstrip()\n",
    "    if header == 'PF':\n",
    "        color = True\n",
    "    elif header == 'Pf':\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Not a PFM file.')\n",
    "\n",
    "    dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', file.readline().decode('utf-8'))\n",
    "    if dim_match:\n",
    "        width, height = map(int, dim_match.groups())\n",
    "    else:\n",
    "        raise Exception('Malformed PFM header.')\n",
    "\n",
    "    scale = float(file.readline().rstrip())\n",
    "    if scale < 0:  # little-endian\n",
    "        endian = '<'\n",
    "        scale = -scale\n",
    "    else:\n",
    "        endian = '>'  # big-endian\n",
    "\n",
    "    data = np.fromfile(file, endian + 'f')\n",
    "    shape = (height, width, 3) if color else (height, width)\n",
    "\n",
    "    data = np.reshape(data, shape)\n",
    "    data = np.flipud(data)\n",
    "    file.close()\n",
    "    return data, scale\n",
    "\n",
    "\n",
    "# read an image\n",
    "def read_img(filename):\n",
    "    img = Image.open(filename)\n",
    "    # scale 0~255 to 0~1\n",
    "    np_img = np.array(img, dtype=np.float32) / 255.\n",
    "    return np_img\n",
    "\n",
    "\n",
    "# read a binary mask\n",
    "def read_mask(filename):\n",
    "    return read_img(filename) > 0.5\n",
    "\n",
    "\n",
    "# save a binary mask\n",
    "def save_mask(filename, mask):\n",
    "    assert mask.dtype == np.bool\n",
    "    mask = mask.astype(np.uint8) * 255\n",
    "    Image.fromarray(mask).save(filename)\n",
    "\n",
    "\n",
    "# read a pair file, [(ref_view1, [src_view1-1, ...]), (ref_view2, [src_view2-1, ...]), ...]\n",
    "def read_pair_file(filename):\n",
    "    data = []\n",
    "    with open(filename) as f:\n",
    "        num_viewpoint = int(f.readline())\n",
    "        # 49 viewpoints\n",
    "        for view_idx in range(num_viewpoint):\n",
    "            ref_view = int(f.readline().rstrip())\n",
    "            src_views = [int(x) for x in f.readline().rstrip().split()[1::2]]\n",
    "            if len(src_views) > 0:\n",
    "                data.append((ref_view, src_views))\n",
    "    return data\n",
    "\n",
    "# torch.no_grad warpper for functions\n",
    "def make_nograd_func(func):\n",
    "    def wrapper(*f_args, **f_kwargs):\n",
    "        with torch.no_grad():\n",
    "            ret = func(*f_args, **f_kwargs)\n",
    "        return ret\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# convert a function into recursive style to handle nested dict/list/tuple variables\n",
    "def make_recursive_func(func):\n",
    "    def wrapper(vars):\n",
    "        if isinstance(vars, list):\n",
    "            return [wrapper(x) for x in vars]\n",
    "        elif isinstance(vars, tuple):\n",
    "            return tuple([wrapper(x) for x in vars])\n",
    "        elif isinstance(vars, dict):\n",
    "            return {k: wrapper(v) for k, v in vars.items()}\n",
    "        else:\n",
    "            return func(vars)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "# a wrapper to compute metrics for each image individually\n",
    "def compute_metrics_for_each_image(metric_func):\n",
    "    def wrapper(depth_est, depth_gt, mask, *args):\n",
    "        batch_size = depth_gt.shape[0]\n",
    "        results = []\n",
    "        # compute result one by one\n",
    "        for idx in range(batch_size):\n",
    "            ret = metric_func(depth_est[idx], depth_gt[idx], mask[idx], *args)\n",
    "            results.append(ret)\n",
    "        return torch.stack(results).mean()\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "def mean_relative_absolute_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the mean relative absolute error (MRAE) between two numpy arrays.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (numpy.array): The ground truth values.\n",
    "    y_pred (numpy.array): The predicted values.\n",
    "\n",
    "    Returns:\n",
    "    float: The MRAE metric result.\n",
    "    \"\"\"\n",
    "    # Avoid division by zero\n",
    "    y_true = np.where(y_true == 0, np.finfo(float).eps, y_true)\n",
    "    \n",
    "    # Calculate MRAE\n",
    "    mrae = np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "    \n",
    "    return mrae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COLMAP Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Copyright (c) 2023, ETH Zurich and UNC Chapel Hill.\n",
    "# All rights reserved.\n",
    "#\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "#     * Redistributions of source code must retain the above copyright\n",
    "#       notice, this list of conditions and the following disclaimer.\n",
    "#\n",
    "#     * Redistributions in binary form must reproduce the above copyright\n",
    "#       notice, this list of conditions and the following disclaimer in the\n",
    "#       documentation and/or other materials provided with the distribution.\n",
    "#\n",
    "#     * Neither the name of ETH Zurich and UNC Chapel Hill nor the names of\n",
    "#       its contributors may be used to endorse or promote products derived\n",
    "#       from this software without specific prior written permission.\n",
    "#\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
    "# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE\n",
    "# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
    "# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
    "# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
    "# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
    "# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
    "# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "# POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "\n",
    "def read_array(path):\n",
    "    with open(path, \"rb\") as fid:\n",
    "        width, height, channels = np.genfromtxt(\n",
    "            fid, delimiter=\"&\", max_rows=1, usecols=(0, 1, 2), dtype=int\n",
    "        )\n",
    "        fid.seek(0)\n",
    "        num_delimiter = 0\n",
    "        byte = fid.read(1)\n",
    "        while True:\n",
    "            if byte == b\"&\":\n",
    "                num_delimiter += 1\n",
    "                if num_delimiter >= 3:\n",
    "                    break\n",
    "            byte = fid.read(1)\n",
    "        array = np.fromfile(fid, np.float32)\n",
    "    array = array.reshape((width, height, channels), order=\"F\")\n",
    "    return np.transpose(array, (1, 0, 2)).squeeze()\n",
    "\n",
    "\n",
    "def write_array(array, path):\n",
    "    \"\"\"\n",
    "    see: src/mvs/mat.h\n",
    "        void Mat<T>::Write(const std::string& path)\n",
    "    \"\"\"\n",
    "    assert array.dtype == np.float32\n",
    "    if len(array.shape) == 2:\n",
    "        height, width = array.shape\n",
    "        channels = 1\n",
    "    elif len(array.shape) == 3:\n",
    "        height, width, channels = array.shape\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    with open(path, \"w\") as fid:\n",
    "        fid.write(str(width) + \"&\" + str(height) + \"&\" + str(channels) + \"&\")\n",
    "\n",
    "    with open(path, \"ab\") as fid:\n",
    "        if len(array.shape) == 2:\n",
    "            array_trans = np.transpose(array, (1, 0))\n",
    "        elif len(array.shape) == 3:\n",
    "            array_trans = np.transpose(array, (1, 0, 2))\n",
    "        else:\n",
    "            assert False\n",
    "        data_1d = array_trans.reshape(-1, order=\"F\")\n",
    "        data_list = data_1d.tolist()\n",
    "        endian_character = \"<\"\n",
    "        format_char_sequence = \"\".join([\"f\"] * len(data_list))\n",
    "        byte_data = struct.pack(\n",
    "            endian_character + format_char_sequence, *data_list\n",
    "        )\n",
    "        fid.write(byte_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MVSNet Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pfm(file):\n",
    "    color = None\n",
    "    width = None\n",
    "    height = None\n",
    "    scale = None\n",
    "    data_type = None\n",
    "    header = file.readline().decode('UTF-8').rstrip()\n",
    "\n",
    "    if header == 'PF':\n",
    "        color = True\n",
    "    elif header == 'Pf':\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Not a PFM file.')\n",
    "    dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', file.readline().decode('UTF-8'))\n",
    "    if dim_match:\n",
    "        width, height = map(int, dim_match.groups())\n",
    "    else:\n",
    "        raise Exception('Malformed PFM header.')\n",
    "    # scale = float(file.readline().rstrip())\n",
    "    scale = float((file.readline()).decode('UTF-8').rstrip())\n",
    "    if scale < 0: # little-endian\n",
    "        data_type = '<f'\n",
    "    else:\n",
    "        data_type = '>f' # big-endian\n",
    "    data_string = file.read()\n",
    "    data = np.fromstring(data_string, data_type)\n",
    "    shape = (height, width, 3) if color else (height, width)\n",
    "    data = np.reshape(data, shape)\n",
    "    data = cv2.flip(data, 0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predicted and Ground-Truth DepthMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GT_DEPTHS_DIR = \"/Users/umairkhawaja/Desktop/workspace/TUM/W23/AD4CV/Depths\"\n",
    "# PRED_DEPTHS_DIR = \"casmvsnet_outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_maes = []\n",
    "# for scene_dir in glob(PRED_DEPTHS_DIR + \"/*\"):\n",
    "#     if not scene_dir.endswith(\".ply\"):\n",
    "#         scene_name = scene_dir.split(\"/\")[-1]\n",
    "#         scene_dmap_dir = join(scene_dir, \"depth_est\")\n",
    "#         scene_mask_dir = join(scene_dir, \"mask\")\n",
    "\n",
    "#         scene_metrics = []\n",
    "#         for pred_dmap_path in glob(scene_dmap_dir + \"/*\"):\n",
    "#             try:\n",
    "#                 filename = pred_dmap_path.split(\"/\")[-1]\n",
    "#                 pred_mask_path = join(scene_mask_dir, filename.replace(\".pfm\", \"_final.png\"))\n",
    "                \n",
    "#                 pfm_num = int(filename.split(\".\")[0])\n",
    "#                 zero_pad = \"000\" if pfm_num < 10 else \"00\"\n",
    "                \n",
    "#                 gt_dmap_path = join(GT_DEPTHS_DIR, scene_name, f\"depth_map_{zero_pad}{pfm_num}.pfm\")\n",
    "#                 gt_mask_path = join(GT_DEPTHS_DIR, scene_name, f\"depth_visual_{zero_pad}{pfm_num}.png\")\n",
    "\n",
    "#                 pred_dmap, pred_scale = read_pfm(pred_dmap_path)\n",
    "#                 gt_dmap, gt_scale = read_pfm(gt_dmap_path)\n",
    "#                 gt_mask = read_mask(gt_mask_path)\n",
    "#                 pred_mask = read_mask(pred_mask_path)\n",
    "\n",
    "#                 gt_dmap = gt_dmap * gt_mask\n",
    "#                 pred_dmap = pred_dmap * pred_mask\n",
    "\n",
    "#                 pred_dmap = pred_dmap.astype(np.float32)\n",
    "#                 pred_dmap = cv2.resize(pred_dmap, (gt_mask.shape[1], gt_mask.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "#                 # Create a figure and a set of subplots\n",
    "#                 fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "#                 # Display Ground truth depth map\n",
    "#                 im1 = ax1.imshow(gt_dmap, cmap='plasma')\n",
    "#                 ax1.set_title('Ground Truth Depth Map')\n",
    "#                 fig.colorbar(im1, ax=ax1)  # Add colorbar for reference\n",
    "\n",
    "#                 # Display Predicted depth map\n",
    "#                 im2 = ax2.imshow(pred_dmap, cmap='plasma')\n",
    "#                 ax2.set_title('Predicted Depth Map')\n",
    "#                 fig.colorbar(im2, ax=ax2)  # Add colorbar for reference\n",
    "\n",
    "\n",
    "#                 pred_dmap_gt_mask = pred_dmap * gt_mask\n",
    "#                 im3 = ax3.imshow(pred_dmap_gt_mask, cmap='plasma')\n",
    "#                 ax3.set_title('Predicted Depth Map with GT Mask')\n",
    "#                 fig.colorbar(im3, ax=ax3)  # Add colorbar for reference\n",
    "\n",
    "\n",
    "#                 mae = np.mean(np.abs(pred_dmap_gt_mask - gt_dmap))\n",
    "#                 mrae = mean_relative_absolute_error(gt_dmap, pred_dmap_gt_mask)\n",
    "\n",
    "#                 plt.suptitle(f\"Error with GT Masking:  MAE {mae:.3f} | MRAE {mrae:.3f}\")\n",
    "                \n",
    "#                 # Save the figure to a JPG file\n",
    "#                 plot_dir = f\"{PRED_DEPTHS_DIR}/plots/{scene_name}/\"\n",
    "#                 Path(plot_dir).mkdir(parents=True, exist_ok=True)\n",
    "#                 fig.savefig(f\"{plot_dir}/{filename.replace('.pfm', '.jpg')}\")\n",
    "#                 plt.close('all')\n",
    "#                 scene_metrics.append(mae)\n",
    "#             except FileNotFoundError as e:\n",
    "#                 print(f\"[MISSING DATA] {e.filename}\")\n",
    "#         scene_error = np.mean(scene_metrics)\n",
    "#         all_maes.append(scene_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(plt.imread(\"/home/dataset/DTU_TEST/scan105/mvsnet_output/00000000.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_depth_map_path = \"/home/dataset/mvs_training/dtu/Rectified/scan3_train/colmap_output/dense/0/stereo/depth_maps/00000000.jpg.geometric.bin\"\n",
    "depth_map = read_array(binary_depth_map_path)\n",
    "min_depth_percentile = 5\n",
    "max_depth_percentile = 95\n",
    "min_depth, max_depth = np.percentile(\n",
    "        depth_map, [min_depth_percentile, max_depth_percentile]\n",
    "    )\n",
    "depth_map[depth_map < min_depth] = min_depth\n",
    "depth_map[depth_map > max_depth] = max_depth\n",
    "\n",
    "import pylab as plt\n",
    "\n",
    "# Visualize the depth map.\n",
    "fig = plt.figure()\n",
    "im = plt.imshow(depth_map, cmap='plasma')\n",
    "fig.colorbar(im)\n",
    "plt.title(\"depth map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Photometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_map = read_array(\"/home/dataset/mvs_training/dtu/Rectified/scan3_train/colmap_output/dense/0/stereo/depth_maps/00000000.jpg.photometric.bin\")\n",
    "min_depth_percentile = 5\n",
    "max_depth_percentile = 95\n",
    "min_depth, max_depth = np.percentile(\n",
    "        depth_map, [min_depth_percentile, max_depth_percentile]\n",
    "    )\n",
    "depth_map[depth_map < min_depth] = min_depth\n",
    "depth_map[depth_map > max_depth] = max_depth\n",
    "\n",
    "import pylab as plt\n",
    "\n",
    "# Visualize the depth map.\n",
    "fig = plt.figure()\n",
    "im = plt.imshow(depth_map, \"plasma\")\n",
    "plt.colorbar(im)\n",
    "plt.title(\"depth map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVSNet Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "depth_path = \"/home/dataset/mvs_training/dtu/MVSNetDepths/scan3_train/depth_map_0000.pfm\"\n",
    "prob_path = \"/home/dataset/mvs_training/dtu/MVSNetProbs/scan3_train/mvsnet_output/prob_map_0000.pfm\"\n",
    "depth_image = load_pfm(open(depth_path, 'rb'))\n",
    "# depth_image, _ = read_pfm(open(depth_path, 'rb'))\n",
    "# prob_image = load_pfm(open(prob_path, 'rb'))\n",
    "# filter_mask = (prob_image > 0.0).astype(np.uint8)\n",
    "# depth_image *= filter_mask\n",
    "ma = np.ma.masked_equal(depth_image, 0.0, copy=False)\n",
    "print('value range: ', ma.min(), ma.max())\n",
    "fig = plt.figure()\n",
    "im = plt.imshow(depth_image, cmap='plasma')\n",
    "fig.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CasMVSNet Predictions -- NOT SUPPORTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# depth_path = \"/home/dataset/mvs_training/dtu/casmvsnet_output/scan100_train/depth_est/00000000.pfm\"\n",
    "# prob_path = \"/home/dataset/mvs_training/dtu/casmvsnet_output/scan100_train/confidence/00000000.pfm\"\n",
    "# depth_image = load_pfm(open(depth_path, 'rb'))\n",
    "# prob_image = load_pfm(open(prob_path, 'rb'))\n",
    "# filter_mask = (prob_image > 0.0).astype(np.uint8)\n",
    "# depth_image *= filter_mask\n",
    "# ma = np.ma.masked_equal(depth_image, 0.0, copy=False)\n",
    "# print('value range: ', ma.min(), ma.max())\n",
    "# fig = plt.figure()\n",
    "# im = plt.imshow(depth_image, cmap='plasma')\n",
    "# fig.colorbar(im)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground-Truth Depth Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap, _ = read_pfm(\"/home/dataset/mvs_training/dtu/Depths_raw/scan3_train/depth_map_0000.pfm\")\n",
    "fig = plt.figure()\n",
    "im = plt.imshow(dmap, 'plasma')\n",
    "plt.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "def load_pfm(file):\n",
    "    \"\"\"\n",
    "    Load a Portable Float Map (PFM) file.\n",
    "    \"\"\"\n",
    "    color = None\n",
    "    width = None\n",
    "    height = None\n",
    "    scale = None\n",
    "    data_type = None\n",
    "    header = file.readline().decode(\"UTF-8\").rstrip()\n",
    "\n",
    "    if header == \"PF\":\n",
    "        color = True\n",
    "    elif header == \"Pf\":\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception(\"Not a PFM file.\")\n",
    "    dim_match = re.match(r\"^(\\d+)\\s(\\d+)\\s$\", file.readline().decode(\"UTF-8\"))\n",
    "    if dim_match:\n",
    "        width, height = map(int, dim_match.groups())\n",
    "    else:\n",
    "        raise Exception(\"Malformed PFM header.\")\n",
    "\n",
    "    scale = float((file.readline()).decode(\"UTF-8\").rstrip())\n",
    "    if scale < 0:  # little-endian\n",
    "        data_type = \"<f\"\n",
    "    else:\n",
    "        data_type = \">f\"  # big-endian\n",
    "\n",
    "    data_string = file.read()\n",
    "    data = np.fromstring(data_string, data_type)\n",
    "    shape = (height, width, 3) if color else (height, width)\n",
    "    data = np.reshape(data, shape)\n",
    "    data = cv2.flip(data, 0)\n",
    "    return data\n",
    "\n",
    "\n",
    "def plot_depth_maps(\n",
    "    gt_paths, pred_paths, n_samples=5, output_path=\"depth_map_comparison.png\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot and save side-by-side comparisons of ground-truth and predicted depth maps.\n",
    "\n",
    "    Args:\n",
    "    - gt_paths (list of str): Paths to ground-truth depth map files.\n",
    "    - pred_paths (list of str): Paths to predicted depth map files.\n",
    "    - n_samples (int): Number of random samples to plot.\n",
    "    - output_path (str): Path to save the output image.\n",
    "    \"\"\"\n",
    "    assert len(gt_paths) == len(\n",
    "        pred_paths\n",
    "    ), \"Ground-truth and prediction lists must have the same length.\"\n",
    "\n",
    "    # Randomly sample n_samples files\n",
    "    if n_samples > len(gt_paths):\n",
    "        n_samples = len(gt_paths)\n",
    "    sampled_indices = random.sample(range(len(gt_paths)), n_samples)\n",
    "\n",
    "    # Number of columns and rows for the plot\n",
    "    ncols = 3\n",
    "    nrows = (n_samples + ncols - 1) // ncols\n",
    "\n",
    "    plt.figure(figsize=(15, 5 * nrows))\n",
    "\n",
    "    for i, idx in enumerate(sampled_indices, 1):\n",
    "        # Load ground-truth depth map\n",
    "        with open(gt_paths[idx], \"rb\") as f:\n",
    "            gt_depth = load_pfm(f)\n",
    "\n",
    "        # Load predicted depth map\n",
    "        with open(pred_paths[idx], \"rb\") as f:\n",
    "            pred_depth = load_pfm(f)\n",
    "\n",
    "        # Plot ground-truth depth map\n",
    "        plt.subplot(nrows, ncols * 2, i * 2 - 1)\n",
    "        plt.imshow(gt_depth, cmap=\"gray\")\n",
    "        plt.title(f\"Ground-Truth {idx}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Plot predicted depth map\n",
    "        plt.subplot(nrows, ncols * 2, i * 2)\n",
    "        plt.imshow(pred_depth, cmap=\"gray\")\n",
    "        plt.title(f\"Prediction {idx}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "# Example usage (paths need to be actual file paths in your environment)\n",
    "pred_paths = glob(\"/home/dataset/mvs_training/dtu/MVSNetDepths/scan100_train/*.pfm\")\n",
    "gt_paths = glob(\"/home/dataset/mvs_training/dtu/Depths_raw/scan100_train/*.pfm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/dataset/mvs_training/dtu/MVSNetDepths/scan100_train/depth_map_0013.pfm',\n",
       " '/home/dataset/mvs_training/dtu/MVSNetDepths/scan100_train/depth_map_0001.pfm',\n",
       " '/home/dataset/mvs_training/dtu/MVSNetDepths/scan100_train/depth_map_0026.pfm',\n",
       " '/home/dataset/mvs_training/dtu/MVSNetDepths/scan100_train/depth_map_0006.pfm',\n",
       " '/home/dataset/mvs_training/dtu/MVSNetDepths/scan100_train/depth_map_0039.pfm',\n",
       " '/home/dataset/mvs_training/dtu/MVSNetDepths/scan100_train/depth_map_0027.pfm',\n",
       " '/home/dataset/mvs_training/dtu/MVSNetDepths/scan100_train/depth_map_0017.pfm',\n",
       " '/home/dataset/mvs_training/dtu/MVSNetDepths/scan100_train/depth_map_0032.pfm',\n",
       " '/home/dataset/mvs_training/dtu/MVSNetDepths/scan100_train/depth_map_0042.pfm',\n",
       " '/home/dataset/mvs_training/dtu/MVSNetDepths/scan100_train/depth_map_0030.pfm']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/dataset/mvs_training/dtu/Depths_raw/scan100_train/depth_map_0013.pfm',\n",
       " '/home/dataset/mvs_training/dtu/Depths_raw/scan100_train/depth_map_0001.pfm',\n",
       " '/home/dataset/mvs_training/dtu/Depths_raw/scan100_train/depth_map_0026.pfm',\n",
       " '/home/dataset/mvs_training/dtu/Depths_raw/scan100_train/depth_map_0006.pfm',\n",
       " '/home/dataset/mvs_training/dtu/Depths_raw/scan100_train/depth_map_0039.pfm',\n",
       " '/home/dataset/mvs_training/dtu/Depths_raw/scan100_train/depth_map_0027.pfm',\n",
       " '/home/dataset/mvs_training/dtu/Depths_raw/scan100_train/depth_map_0017.pfm',\n",
       " '/home/dataset/mvs_training/dtu/Depths_raw/scan100_train/depth_map_0032.pfm',\n",
       " '/home/dataset/mvs_training/dtu/Depths_raw/scan100_train/depth_map_0042.pfm',\n",
       " '/home/dataset/mvs_training/dtu/Depths_raw/scan100_train/depth_map_0030.pfm']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2902368/2766106313.py:39: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  data = np.fromstring(data_string, data_type)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'depth_map_comparison.png'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_depth_maps(gt_paths, pred_paths, n_samples=6, output_path=\"depth_map_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "volrecon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
