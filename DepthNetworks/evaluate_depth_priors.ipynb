{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "def read_pfm(filename):\n",
    "    file = open(filename, 'rb')\n",
    "    color = None\n",
    "    width = None\n",
    "    height = None\n",
    "    scale = None\n",
    "    endian = None\n",
    "\n",
    "    header = file.readline().decode('utf-8').rstrip()\n",
    "    if header == 'PF':\n",
    "        color = True\n",
    "    elif header == 'Pf':\n",
    "        color = False\n",
    "    else:\n",
    "        raise Exception('Not a PFM file.')\n",
    "\n",
    "    dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', file.readline().decode('utf-8'))\n",
    "    if dim_match:\n",
    "        width, height = map(int, dim_match.groups())\n",
    "    else:\n",
    "        raise Exception('Malformed PFM header.')\n",
    "\n",
    "    scale = float(file.readline().rstrip())\n",
    "    if scale < 0:  # little-endian\n",
    "        endian = '<'\n",
    "        scale = -scale\n",
    "    else:\n",
    "        endian = '>'  # big-endian\n",
    "\n",
    "    data = np.fromfile(file, endian + 'f')\n",
    "    shape = (height, width, 3) if color else (height, width)\n",
    "\n",
    "    data = np.reshape(data, shape)\n",
    "    data = np.flipud(data)\n",
    "    file.close()\n",
    "    return data, scale\n",
    "\n",
    "\n",
    "\n",
    "# read an image\n",
    "def read_img(filename):\n",
    "    img = Image.open(filename)\n",
    "    # scale 0~255 to 0~1\n",
    "    np_img = np.array(img, dtype=np.float32) / 255.\n",
    "    return np_img\n",
    "\n",
    "\n",
    "# read a binary mask\n",
    "def read_mask(filename):\n",
    "    return read_img(filename) > 0.5\n",
    "\n",
    "\n",
    "# save a binary mask\n",
    "def save_mask(filename, mask):\n",
    "    assert mask.dtype == np.bool\n",
    "    mask = mask.astype(np.uint8) * 255\n",
    "    Image.fromarray(mask).save(filename)\n",
    "\n",
    "\n",
    "# read a pair file, [(ref_view1, [src_view1-1, ...]), (ref_view2, [src_view2-1, ...]), ...]\n",
    "def read_pair_file(filename):\n",
    "    data = []\n",
    "    with open(filename) as f:\n",
    "        num_viewpoint = int(f.readline())\n",
    "        # 49 viewpoints\n",
    "        for view_idx in range(num_viewpoint):\n",
    "            ref_view = int(f.readline().rstrip())\n",
    "            src_views = [int(x) for x in f.readline().rstrip().split()[1::2]]\n",
    "            if len(src_views) > 0:\n",
    "                data.append((ref_view, src_views))\n",
    "    return data\n",
    "\n",
    "# torch.no_grad warpper for functions\n",
    "def make_nograd_func(func):\n",
    "    def wrapper(*f_args, **f_kwargs):\n",
    "        with torch.no_grad():\n",
    "            ret = func(*f_args, **f_kwargs)\n",
    "        return ret\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# convert a function into recursive style to handle nested dict/list/tuple variables\n",
    "def make_recursive_func(func):\n",
    "    def wrapper(vars):\n",
    "        if isinstance(vars, list):\n",
    "            return [wrapper(x) for x in vars]\n",
    "        elif isinstance(vars, tuple):\n",
    "            return tuple([wrapper(x) for x in vars])\n",
    "        elif isinstance(vars, dict):\n",
    "            return {k: wrapper(v) for k, v in vars.items()}\n",
    "        else:\n",
    "            return func(vars)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "# a wrapper to compute metrics for each image individually\n",
    "def compute_metrics_for_each_image(metric_func):\n",
    "    def wrapper(depth_est, depth_gt, mask, *args):\n",
    "        batch_size = depth_gt.shape[0]\n",
    "        results = []\n",
    "        # compute result one by one\n",
    "        for idx in range(batch_size):\n",
    "            ret = metric_func(depth_est[idx], depth_gt[idx], mask[idx], *args)\n",
    "            results.append(ret)\n",
    "        return torch.stack(results).mean()\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@make_nograd_func\n",
    "@compute_metrics_for_each_image\n",
    "def Thres_metrics(depth_est, depth_gt, mask, thres):\n",
    "    assert isinstance(thres, (int, float))\n",
    "    depth_est, depth_gt = depth_est[mask], depth_gt[mask]\n",
    "    errors = torch.abs(depth_est - depth_gt)\n",
    "    err_mask = errors > thres\n",
    "    return torch.mean(err_mask.float())\n",
    "\n",
    "\n",
    "# NOTE: please do not use this to build up training loss\n",
    "@make_nograd_func\n",
    "@compute_metrics_for_each_image\n",
    "def AbsDepthError_metrics(depth_est, depth_gt, mask, thres=None):\n",
    "    depth_est, depth_gt = depth_est[mask], depth_gt[mask]\n",
    "    error = (depth_est - depth_gt).abs()\n",
    "    if thres is not None:\n",
    "        error = error[(error >= float(thres[0])) & (error <= float(thres[1]))]\n",
    "        if error.shape[0] == 0:\n",
    "            return torch.tensor(0, device=error.device, dtype=error.dtype)\n",
    "    return torch.mean(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_DEPTHS_DIR = \"/Users/umairkhawaja/Downloads/Depths/\"\n",
    "PRED_DEPTHS_DIR = \"mvsnet_outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/umairkhawaja/Desktop/workspace/TUM/W23/AD4CV/VolReconWithDepthPriors/DepthNetworks/evaluate_depth_priors.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/umairkhawaja/Desktop/workspace/TUM/W23/AD4CV/VolReconWithDepthPriors/DepthNetworks/evaluate_depth_priors.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/umairkhawaja/Desktop/workspace/TUM/W23/AD4CV/VolReconWithDepthPriors/DepthNetworks/evaluate_depth_priors.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/umairkhawaja/Desktop/workspace/TUM/W23/AD4CV/VolReconWithDepthPriors/DepthNetworks/evaluate_depth_priors.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_io\u001b[39;00m \u001b[39mimport\u001b[39;00m read_pfm  \u001b[39m# Ensure this import path is correct for read_pfm function\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/umairkhawaja/Desktop/workspace/TUM/W23/AD4CV/VolReconWithDepthPriors/DepthNetworks/evaluate_depth_priors.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_depth_maps_from_pfm\u001b[39m(directory):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/umairkhawaja/Desktop/workspace/TUM/W23/AD4CV/VolReconWithDepthPriors/DepthNetworks/evaluate_depth_priors.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# List all files in the given directory\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/umairkhawaja/Desktop/workspace/TUM/W23/AD4CV/VolReconWithDepthPriors/DepthNetworks/evaluate_depth_priors.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m root, dirs, files \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mwalk(directory):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets.data_io import read_pfm  # Ensure this import path is correct for read_pfm function\n",
    "\n",
    "def plot_depth_maps_from_pfm(directory):\n",
    "    # List all files in the given directory\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check for .pfm extension\n",
    "            if file.endswith('.pfm'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Read the depth map from .pfm file\n",
    "                depth_map, _ = read_pfm(file_path)\n",
    "\n",
    "                # Plotting the depth map\n",
    "                fig = plt.figure(figsize=(10, 5))\n",
    "                plt.imshow(depth_map, cmap='plasma')  # 'plasma' colormap is good for depth maps\n",
    "                plt.colorbar()\n",
    "                plt.title(f'Depth Map: {root}/{file}')\n",
    "                fig.savefig(file_path.replace(\".pfm\", \".jpg\"))\n",
    "                plt.show()\n",
    "                plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_relative_absolute_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the mean relative absolute error (MRAE) between two numpy arrays.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (numpy.array): The ground truth values.\n",
    "    y_pred (numpy.array): The predicted values.\n",
    "\n",
    "    Returns:\n",
    "    float: The MRAE metric result.\n",
    "    \"\"\"\n",
    "    # Avoid division by zero\n",
    "    y_true = np.where(y_true == 0, np.finfo(float).eps, y_true)\n",
    "    \n",
    "    # Calculate MRAE\n",
    "    mrae = np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "    \n",
    "    return mrae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Assuming PRED_DEPTHS_DIR and GT_DEPTHS_DIR are defined, \n",
    "# along with read_pfm and read_mask functions\n",
    "\n",
    "all_maes = []\n",
    "for scene_dir in glob(PRED_DEPTHS_DIR + \"/*\"):\n",
    "    if not scene_dir.endswith(\".ply\"):\n",
    "        scene_name = scene_dir.split(\"/\")[-1]\n",
    "        scene_dmap_dir = join(scene_dir, \"depth_est\")\n",
    "        scene_mask_dir = join(scene_dir, \"mask\")\n",
    "\n",
    "        scene_metrics = []\n",
    "        for pred_dmap_path in glob(scene_dmap_dir + \"/*\"):\n",
    "            filename = pred_dmap_path.split(\"/\")[-1]\n",
    "            pred_mask_path = join(scene_mask_dir, filename.replace(\".pfm\", \"_final.png\"))\n",
    "            \n",
    "            pfm_num = int(filename.split(\".\")[0])\n",
    "            zero_pad = \"000\" if pfm_num < 10 else \"00\"\n",
    "            \n",
    "            gt_dmap_path = join(GT_DEPTHS_DIR, scene_name, f\"depth_map_{zero_pad}{pfm_num}.pfm\")\n",
    "            gt_mask_path = join(GT_DEPTHS_DIR, scene_name, f\"depth_visual_{zero_pad}{pfm_num}.png\")\n",
    "\n",
    "            pred_dmap, pred_scale = read_pfm(pred_dmap_path)\n",
    "            gt_dmap, gt_scale = read_pfm(gt_dmap_path)\n",
    "            gt_mask = read_mask(gt_mask_path)\n",
    "            pred_mask = read_mask(pred_mask_path)\n",
    "\n",
    "            gt_dmap = gt_dmap * gt_mask\n",
    "            pred_dmap = pred_dmap * pred_mask\n",
    "\n",
    "            pred_dmap = pred_dmap.astype(np.float32)\n",
    "            pred_dmap = cv2.resize(pred_dmap, (gt_mask.shape[1], gt_mask.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            # Create a figure and a set of subplots\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "            # Display Ground truth depth map\n",
    "            im1 = ax1.imshow(gt_dmap, cmap='plasma')\n",
    "            ax1.set_title('Ground Truth Depth Map')\n",
    "            fig.colorbar(im1, ax=ax1)  # Add colorbar for reference\n",
    "\n",
    "            # Display Predicted depth map\n",
    "            im2 = ax2.imshow(pred_dmap, cmap='plasma')\n",
    "            ax2.set_title('Predicted Depth Map')\n",
    "            fig.colorbar(im2, ax=ax2)  # Add colorbar for reference\n",
    "\n",
    "\n",
    "            pred_dmap_gt_mask = pred_dmap * gt_mask\n",
    "            im3 = ax3.imshow(pred_dmap_gt_mask, cmap='plasma')\n",
    "            ax3.set_title('Predicted Depth Map with GT Mask')\n",
    "            fig.colorbar(im3, ax=ax3)  # Add colorbar for reference\n",
    "\n",
    "\n",
    "            mae = np.mean(np.abs(pred_dmap_gt_mask - gt_dmap))\n",
    "            mrae = mean_relative_absolute_error(gt_dmap, pred_dmap_gt_mask)\n",
    "            print(mae, mrae)\n",
    "\n",
    "            plt.suptitle(f\"Error with GT Masking:  MAE {mae:.3f} | MRAE {mrae:.3f}\")\n",
    "            \n",
    "            # Save the figure to a JPG file\n",
    "            plot_dir = f\"mvsnet_outputs/plots/{scene_name}/\"\n",
    "            Path(plot_dir).mkdir(parents=True, exist_ok=True)\n",
    "            fig.savefig(f\"{plot_dir}/{filename.replace('.pfm', '.jpg')}\")\n",
    "            plt.close('all')\n",
    "            scene_metrics.append(mae)\n",
    "        scene_error = np.mean(scene_metrics)\n",
    "        all_maes.append(scene_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(np.array(all_maes[:-1])) | MVSNET: 136mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "volrecon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
